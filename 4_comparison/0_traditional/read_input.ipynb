{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_func import *\n",
    "from sits_func import *\n",
    "from res_func import *\n",
    "from tensorflow.python.lib.io import file_io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input\\fcTS_train_ssize10_tyear2002_LCfinalmapv6_LCProp2.csv'\n",
    "test_file = r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input\\fcTS_test_ssize10_tyear2002_LCfinalmapv6_LCProp2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "ids_train = []\n",
    "X_test  = []\n",
    "y_test =[]\n",
    "ids_test = []\n",
    "\n",
    "years=range(2001,2003)\n",
    "ssize=10\n",
    "\n",
    "for y in years:\n",
    "    train_x, train_ids, train_y = readSITSData(r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input\\fcTS_train_ssize{}_tyear{}_LCfinalmapv6_LCProp2.csv'.format(ssize,y),y )\n",
    "    test_x, test_ids, test_y = readSITSData(r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input\\fcTS_train_ssize{}_tyear{}_LCfinalmapv6_LCProp2.csv'.format(ssize,y),y )\n",
    "    \n",
    "    X_train.append(train_x)\n",
    "    y_train.append(train_y)\n",
    "    ids_train.append(train_ids)\n",
    "\n",
    "    X_test.append(test_x)\n",
    "    y_test.append(test_y)\n",
    "    ids_test.append(test_ids)\n",
    "\n",
    "target_X = [X_train, X_test]\n",
    "target_others = [y_train, ids_train, y_test, ids_test]\n",
    "X_train, X_test = [np.vstack(t) for t in target_X]\n",
    "y_train, ids_train, y_test, ids_test = [np.array(t).flatten() for t in target_others]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_idxs(y,N_largest):\n",
    "    count, bins = np.histogram(y, bins=np.unique(y))\n",
    "    classidxs_by_size = count.argsort()[::-1]\n",
    "    return classidxs_by_size[:N_largest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_largest(X, y, ids, class_idxs):\n",
    "    print(y.flatten().shape)\n",
    "    mask = np.isin(y.flatten(), class_idxs)\n",
    "    y = y.flatten()[mask]\n",
    "    X = X[mask]\n",
    "    ids = ids.flatten()[mask]\n",
    "    return X, y, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_idxs(targets, N_uniform=50):\n",
    "    classes = np.unique(targets)\n",
    "    idxs = np.array([])\n",
    "    for c in classes:\n",
    "        idxs_ = np.argwhere(targets == c)[:N_uniform, 0]\n",
    "        idxs = np.hstack([idxs, idxs_])\n",
    "    return idxs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uniform(X, y, ids, N_uniform):\n",
    "    idxs = get_uniform_idxs(y, N_uniform)\n",
    "    y = y[idxs]\n",
    "    X = X[idxs]\n",
    "    ids = ids[idxs]\n",
    "    return X, y, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.path.join(r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input','classes_MCD12Q1v6raw_LCProp2.txt')\n",
    "with file_io.FileIO(classes, 'r') as f:  # gcp\n",
    "    classnames = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0|unknown\\n', '1|Barren\\n', '2|Permanent Snow and Ice\\n',\n",
       "       '3|Water Bodies\\n', '4|Urban and Builtup Lands\\n',\n",
       "       '5|Dense Forests\\n', '6|Open Forests\\n',\n",
       "       '7|Forest Cropland Mosaics\\n', '8|Natural Herbaceous\\n',\n",
       "       '9|Natural Herbaceous Croplands Mosaics\\n',\n",
       "       '10|Herbaceous Croplands\\n', '11|Shrublands\\n'], dtype='<U39')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180,)\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "class_idxs = get_class_idxs(np.hstack([y_train,y_test]),True)\n",
    "X, y, ids = filter_largest(X_train, y_train, ids_train, class_idxs)\n",
    "Xtest, ytest, idstest = filter_largest(X_test, y_test, ids_test, class_idxs)\n",
    "classnames = np.array(classnames)[class_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idxs = np.arange(len(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make uniform class distributions\n",
    "X, y, ids = make_uniform(X, y, ids, 2)\n",
    "Xtest, ytest, idstest = make_uniform(Xtest, ytest, idstest, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make uniform class distributions\n",
    "X, y, ids = make_uniform(X_train, y_train, ids_train, 2)\n",
    "Xtest, ytest, idstest = make_uniform(X_test, y_test, ids_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 158,\n",
       "         2: 1000,\n",
       "         3: 1000,\n",
       "         4: 1000,\n",
       "         5: 1000,\n",
       "         6: 1000,\n",
       "         7: 1000,\n",
       "         9: 1000,\n",
       "         10: 1000})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2001\n",
    "train_file = r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input\\fcTS_train_ssize10_tyear{}_LCfinalmapv6_LCProp2.csv'.format(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\acoca\\\\research\\\\gee\\\\dataset\\\\AMZ\\\\comparison\\\\input\\\\fcTS_train_ssize10_tyear2001_LCfinalmapv6_LCProp2.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\acocac\\research\\scripts\\MTLCC-MODIS-GCP\\4_comparison\\0_traditional\\sits_func.py:79: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  data = pd.read_table(name_file, sep=',', header=0)  # -- one header\n"
     ]
    }
   ],
   "source": [
    "X_train = [readSITSData(r'F:\\acoca\\research\\gee\\dataset\\AMZ\\comparison\\input\\fcTS_train_ssize1000_tyear{}_LCfinalmapv6_LCProp2.csv'.format(year), year) for year in range(2001,2003)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (90,368) into shape (90)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f8b3c7340327>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (90,368) into shape (90)"
     ]
    }
   ],
   "source": [
    "np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 743.,  361.,  281., ...,  345.,  353.,  361.],\n",
       "       [ 975.,  788.,  289., ...,  345.,  353.,  361.],\n",
       "       [ 723.,  544.,  285., ...,  345.,  353.,  361.],\n",
       "       ...,\n",
       "       [ 555., 3680.,  304., ...,  345.,  353.,  361.],\n",
       "       [ 493., 2897.,  259., ...,  345.,  353.,  361.],\n",
       "       [ 880., 2852.,  452., ...,  345.,  353.,  361.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [np.concatenate([X[t][1],doy]) for t in range(len(X_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAPAZ\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36_keras\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_table(train_file, sep=',', header=0)  # -- one header\n",
    "\n",
    "y_data = data['class'] - 1\n",
    "\n",
    "y = np.asarray(y_data.values, dtype='uint8')\n",
    "\n",
    "data[ 'array' ] = data[ 'array' ].apply(lambda s: list(literal_eval(s)))\n",
    "data[ 'array' ] = data[ 'array' ].apply(lambda s: np.concatenate(np.array(s)))\n",
    "\n",
    "x = np.array(data[ 'array' ]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\acoca\\\\research\\\\gee\\\\dataset\\\\AMZ\\\\comparison\\\\input\\\\fcTS_train_ssize10_tyear2001_LCfinalmapv6_LCProp2.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_keras]",
   "language": "python",
   "name": "conda-env-py36_keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

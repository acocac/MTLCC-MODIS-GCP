{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "indir = r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\geodata\\blocks\\384\\raw\"\n",
    "\n",
    "df_patchid = gpd.read_file(os.path.join(indir, 'patchid.geojson'))\n",
    "df_fileid = gpd.read_file(os.path.join(indir, 'fileid.geojson'))\n",
    "\n",
    "df_all = gpd.overlay(df_patchid,df_fileid,how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['id_fn'] = df_all.patch_id.astype(str) + '_' +  df_all.file_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAPAZ\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_all, eval_data = train_test_split(df_all['id_fn'], test_size = 1/6,  random_state=42)\n",
    "\n",
    "outdir = r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\geodata\\blocks\\384\\splits\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "        \n",
    "np.savetxt(os.path.join(outdir,\"eval.tileids\"), np.array(eval_data).astype(str),fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##train and test\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "rs = ShuffleSplit(n_splits=10, test_size=1/5,  random_state=42)\n",
    "i = 0\n",
    "for train_index, test_index in rs.split(train_all):\n",
    "    i = i + 1\n",
    "    train_all = np.array(train_all)\n",
    "    train_data = train_all[train_index]\n",
    "    test_data = train_all[test_index]\n",
    "    np.savetxt(os.path.join(outdir,\"train_fold\" + str(i-1) + \".tileids\"), np.array(train_data).astype(str),fmt='%s')\n",
    "    np.savetxt(os.path.join(outdir,\"test_fold\" + str(i-1) + \".tileids\"), np.array(test_data).astype(str),fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "indir = r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\geodata\\blocks\\384\\splits\"\n",
    "\n",
    "traintiles = np.loadtxt(os.path.join(indir,\"train_fold0.tileids\"), dtype='str')\n",
    "testtiles = np.loadtxt(os.path.join(indir,\"test_fold0.tileids\"), dtype='str')\n",
    "evaltiles = np.loadtxt(os.path.join(indir,\"eval.tileids\"), dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesnm = []\n",
    "for root, dirs, files in os.walk(r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\gz\\24\\MCD12Q1v6\\data09\"):  \n",
    "    for name in files:        \n",
    "        if name.endswith(\".gz\"):  \n",
    "            # shapefile name without extension  \n",
    "            fname, ext = name.split('.')\n",
    "            filesnm.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesnm_df = pd.DataFrame(filesnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = {0:'file',1:'id_fn'}\n",
    "\n",
    "filesnm_df = filesnm_df.iloc[:,0].str.split('_', 1, expand=True).rename(columns = names)\n",
    "filesnm_df['file_nm'] = filesnm_df['file'].astype(str) + '_' + filesnm_df['id_fn'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\gz\\24\\MCD12Q1v6\\tileids\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "np.savetxt(os.path.join(outdir,\"train_fold\" + str(0) + \".tileids\"), np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(traintiles),'file_nm']).astype(str),fmt='%s')\n",
    "np.savetxt(os.path.join(outdir,\"test_fold\" + str(0) + \".tileids\"), np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(testtiles),'file_nm']).astype(str),fmt='%s')\n",
    "np.savetxt(os.path.join(outdir,\"eval.tileids\"), np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(evaltiles),'file_nm']).astype(str),fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files =  (4608,)\n"
     ]
    }
   ],
   "source": [
    "print('Total files = ', filesnm_df.loc[filesnm_df['id_fn'].isin(np.concatenate([traintiles,testtiles,evaltiles])),'file_nm'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.loc[df_all['id_fn'].isin(traintiles),'split'] = 0\n",
    "df_all.loc[df_all['id_fn'].isin(testtiles),'split'] = 1\n",
    "df_all.loc[df_all['id_fn'].isin(evaltiles),'split'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.to_file(driver = 'ESRI Shapefile', filename= os.path.join(indir,\"split.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.to_file(driver=\"GeoJSON\",filename= os.path.join(r'F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\geodata\\blocks\\384','split.geojson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config2 = configparser.ConfigParser()\n",
    "config2['2009'] = {'pix250': '24',\n",
    "                   'nbands250': '7',\n",
    "                   'nbands500': '5',\n",
    "                   'nobs': '46',\n",
    "                   'datadir': 'data09',\n",
    "                   'sqlwhere': '\"where date is not null and year=2001\"',\n",
    "                   'tiletable': 'tiles23',\n",
    "                   'fieldtable': 'fields2009',\n",
    "                   'level': 'L1C'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\gz\\24\\MCD12Q1v6\\dataset.ini', 'w') as configfile:\n",
    "    config2.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create geotransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "filesnm = []\n",
    "for root, dirs, files in os.walk(r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\gz\\24\\MCD12Q1v6\\data09\"):  \n",
    "    for name in files:        \n",
    "        if name.endswith(\".gz\"):  \n",
    "            # shapefile name without extension  \n",
    "            fname, ext = name.split('.')\n",
    "            filesnm.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_1 = pd.DataFrame(filesnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_1['1'] = 0\n",
    "col_1['2'] = 250\n",
    "col_1['3'] = 0\n",
    "col_1['4'] = 0\n",
    "col_1['5'] = 0\n",
    "col_1['6'] = -250\n",
    "col_1['7'] = 32632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_1.to_csv(r\"F:\\acoca\\research\\gee\\dataset\\test\\MOD09_250m500m\\gz\\24\\MCD12Q1v6\\geotransforms.csv\", index= None, header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split tiles 250m data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "indir = r\"F:\\acoca\\research\\gee\\dataset\\final\\geodata\\ids\\p207_250m\\final\"\n",
    "\n",
    "df_split = gpd.read_file(os.path.join(indir, 'AMZ_p207k0_250m.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesnm = []\n",
    "for root, dirs, files in os.walk(r\"F:\\acoca\\research\\gee\\dataset\\final\\MOD13Q1_250m\\gz\\69\\MCD12Q1v6\\data09\"):  \n",
    "    for name in files:        \n",
    "        if name.endswith(\".gz\"):  \n",
    "            # shapefile name without extension  \n",
    "            fname, ext = name.split('.')\n",
    "            filesnm.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesnm_df = pd.DataFrame(filesnm)\n",
    "names = {0:'file',1:'id_fn'}\n",
    "\n",
    "filesnm_df = filesnm_df.iloc[:,0].str.split('_', 1, expand=True).rename(columns = names)\n",
    "filesnm_df['file_nm'] = filesnm_df['file'].astype(str) + '_' + filesnm_df['id_fn'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = r\"F:\\acoca\\research\\gee\\dataset\\final\\MOD13Q1_250m\\gz\\69\\MCD12Q1v6\\tileids\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "np.savetxt(os.path.join(outdir,\"train_fold\" + str(0) + \".tileids\"), np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(np.array(df_split[df_split.split == 0].id_fn)),'file_nm']).astype(str),fmt='%s')\n",
    "np.savetxt(os.path.join(outdir,\"test_fold\" + str(0) + \".tileids\"), np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(np.array(df_split[df_split.split == 1].id_fn)),'file_nm']).astype(str),fmt='%s')\n",
    "np.savetxt(os.path.join(outdir,\"eval.tileids\"), np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(np.array(df_split[df_split.split == 2].id_fn)),'file_nm']).astype(str),fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(filesnm_df.loc[filesnm_df['id_fn'].isin(np.array(df_split[df_split.split == 2].id_fn)),'file_nm']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3978 3978\n"
     ]
    }
   ],
   "source": [
    "options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "\n",
    "fileNames_250m = sorted(glob.glob(r'F:\\acoca\\research\\gee\\dataset\\final\\MOD09_250m500m\\raw\\192\\data09\\*.gz'),key=os.path.getmtime)\n",
    "fileNames_500m = sorted(glob.glob(r'F:\\acoca\\research\\gee\\dataset\\final\\MOD09_250m500m\\raw\\96\\data09\\*.gz'),key=os.path.getmtime)\n",
    "\n",
    "n_patches_first = sum(1 for _ in tf.python_io.tf_record_iterator(fileNames_250m[0], options=options))\n",
    "n_patches_last = sum(1 for _ in tf.python_io.tf_record_iterator(fileNames_250m[-1], options=options))\n",
    "\n",
    "batchsize_merge = n_patches_first\n",
    "\n",
    "tfiles_250m = (n_patches_first * (len(fileNames_250m)-1)) + n_patches_last\n",
    "\n",
    "n_patches_first = sum(1 for _ in tf.python_io.tf_record_iterator(fileNames_500m[0], options=options))\n",
    "n_patches_last = sum(1 for _ in tf.python_io.tf_record_iterator(fileNames_500m[-1], options=options))\n",
    "\n",
    "tfiles_500m = (n_patches_first * (len(fileNames_500m)-1)) + n_patches_last\n",
    "\n",
    "print(tfiles_250m, tfiles_500m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
